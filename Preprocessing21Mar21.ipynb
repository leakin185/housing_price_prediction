{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import researchpy as rp\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() # set the default Seaborn style for graphics\n",
    "from scipy import stats\n",
    "from scipy.stats import skew \n",
    "from sklearn.model_selection import train_test_split\n",
    "# machine learning library\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "# computational time\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the csv dataset\n",
    "train = pd.read_csv('train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with null data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FROM EDA:\n",
    "\n",
    "LotFrontage /number of null data: 259\n",
    "\n",
    "MasVnrType /number of null data: 8\n",
    "\n",
    "MasVnrArea /number of null data: 8\n",
    "\n",
    "Electrical /number of null data: 1\n",
    "\n",
    "GarageYrBlt /number of null data: 81\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For feature with too many missing values, remove this feature entirely. \n",
    "- Set treshold to be 10% of all data points\n",
    "\n",
    "For feature with only a few missing values, remove that data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop feature - too many nulls:\n",
      "LotFrontage\n",
      "Remove data point:\n",
      "['MasVnrType', 'MasVnrArea', 'Electrical', 'GarageYrBlt']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotArea Street Alley LotShape LandContour  \\\n",
       "0   1          60       RL     8450   Pave   NaN      Reg         Lvl   \n",
       "1   2          20       RL     9600   Pave   NaN      Reg         Lvl   \n",
       "2   3          60       RL    11250   Pave   NaN      IR1         Lvl   \n",
       "3   4          70       RL     9550   Pave   NaN      IR1         Lvl   \n",
       "4   5          60       RL    14260   Pave   NaN      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0    AllPub    Inside  ...        0    NaN   NaN         NaN       0      2   \n",
       "1    AllPub       FR2  ...        0    NaN   NaN         NaN       0      5   \n",
       "2    AllPub    Inside  ...        0    NaN   NaN         NaN       0      9   \n",
       "3    AllPub    Corner  ...        0    NaN   NaN         NaN       0      2   \n",
       "4    AllPub       FR2  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "   YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0    2008        WD         Normal     208500  \n",
       "1    2007        WD         Normal     181500  \n",
       "2    2008        WD         Normal     223500  \n",
       "3    2006        WD        Abnorml     140000  \n",
       "4    2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nullData = [['LotFrontage', 259], ['MasVnrType', 8], ['MasVnrArea', 8], ['Electrical', 1], ['GarageYrBlt', 81]]\n",
    "n = len(train)\n",
    "treshold = 0.1\n",
    "drop = []\n",
    "\n",
    "print('Drop feature - too many nulls:')\n",
    "for i in nullData:\n",
    "    if i[1]/n > treshold: # Arbitrary treshold: 10%\n",
    "        print(i[0])\n",
    "        train.drop(columns=[i[0]], inplace=True)\n",
    "    else:\n",
    "        drop.append(i[0])\n",
    "        \n",
    "print('Remove data point:')\n",
    "print(drop)\n",
    "train.dropna(subset=drop, inplace=True)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 80\n",
      "Number of data: 1370\n"
     ]
    }
   ],
   "source": [
    "print('Number of columns:', len(train.columns))\n",
    "print('Number of data:', len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with highly skewed categorical features\n",
    "\n",
    "As identifited from data exploration, we removed categorical variables with one category of data occuping >= 90% of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of variables with one category of data which occupies >= 90% of data = 15\n",
      "Street /ratio of the dominant category =  0.9964\n",
      "LandContour /ratio of the dominant category =  0.9015000000000001\n",
      "Utilities /ratio of the dominant category =  0.9993000000000001\n",
      "LandSlope /ratio of the dominant category =  0.9467\n",
      "Condition2 /ratio of the dominant category =  0.9898\n",
      "RoofMatl /ratio of the dominant category =  0.9818000000000001\n",
      "BsmtCond /ratio of the dominant category =  0.9246\n",
      "Heating /ratio of the dominant category =  0.981\n",
      "CentralAir /ratio of the dominant category =  0.9495999999999999\n",
      "Electrical /ratio of the dominant category =  0.9226000000000001\n",
      "Functional /ratio of the dominant category =  0.9336\n",
      "GarageQual /ratio of the dominant category =  0.9504\n",
      "GarageCond /ratio of the dominant category =  0.9612999999999999\n",
      "PavedDrive /ratio of the dominant category =  0.9372\n",
      "MiscFeature /ratio of the dominant category =  0.9216\n"
     ]
    }
   ],
   "source": [
    "categorical = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond','Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n",
    "#skewness of categorical variables\n",
    "max_percent = []\n",
    "catogorical_skewed=[]\n",
    "for i in categorical: \n",
    "    if rp.summary_cat(train[i])[\"Percent\"].max() >= 90: \n",
    "        max_percent.append(rp.summary_cat(train[i])[\"Percent\"].max())\n",
    "print (\"The number of variables with one category of data which occupies >= 90% of data =\", len(max_percent))\n",
    "#highly skewed categorical variables\n",
    "for i in categorical: \n",
    "    if rp.summary_cat(train[i])[\"Percent\"].max() >= 90:\n",
    "        catogorical_skewed.append(i)\n",
    "        print (i,\"/ratio of the dominant category = \", rp.summary_cat(train[i])[\"Percent\"].max()/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in catogorical_skewed:\n",
    "    train.drop(columns=[i], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of variables with one category of data which occupies >= 90% of data = 0\n"
     ]
    }
   ],
   "source": [
    "for i in catogorical_skewed:\n",
    "    categorical.remove(i)\n",
    "#skewness of categorical variables\n",
    "max_percent = []\n",
    "for i in categorical: \n",
    "    if rp.summary_cat(train[i])[\"Percent\"].max() >= 90: \n",
    "        max_percent.append(rp.summary_cat(train[i])[\"Percent\"].max())\n",
    "print (\"The number of variables with one category of data which occupies >= 90% of data =\", len(max_percent))\n",
    "#highly skewed categorical variables\n",
    "for i in categorical: \n",
    "    if rp.summary_cat(train[i])[\"Percent\"].max() >= 90: \n",
    "         print (i,\"/ratio of the dominant category = \", rp.summary_cat(train[i])[\"Percent\"].max()/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8450</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>856</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9600</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11250</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>920</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9550</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>961</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>14260</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>1145</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 248 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  LotArea  YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0   1     8450       2003          2003       196.0         706           0   \n",
       "1   2     9600       1976          1976         0.0         978           0   \n",
       "2   3    11250       2001          2002       162.0         486           0   \n",
       "3   4     9550       1915          1970         0.0         216           0   \n",
       "4   5    14260       2000          2000       350.0         655           0   \n",
       "\n",
       "   BsmtUnfSF  TotalBsmtSF  1stFlrSF  ...  SaleType_ConLw  SaleType_New  \\\n",
       "0        150          856       856  ...               0             0   \n",
       "1        284         1262      1262  ...               0             0   \n",
       "2        434          920       920  ...               0             0   \n",
       "3        540          756       961  ...               0             0   \n",
       "4        490         1145      1145  ...               0             0   \n",
       "\n",
       "   SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
       "0             0            1                      0                      0   \n",
       "1             0            1                      0                      0   \n",
       "2             0            1                      0                      0   \n",
       "3             0            1                      1                      0   \n",
       "4             0            1                      0                      0   \n",
       "\n",
       "   SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
       "0                     0                     0                     1   \n",
       "1                     0                     0                     1   \n",
       "2                     0                     0                     1   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     1   \n",
       "\n",
       "   SaleCondition_Partial  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 248 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.get_dummies(train, columns= categorical, prefix= categorical)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1370, 248)\n",
      "Dtypes:\n",
      " Id                         int64\n",
      "LotArea                    int64\n",
      "YearBuilt                  int64\n",
      "YearRemodAdd               int64\n",
      "MasVnrArea               float64\n",
      "                          ...   \n",
      "SaleCondition_AdjLand      uint8\n",
      "SaleCondition_Alloca       uint8\n",
      "SaleCondition_Family       uint8\n",
      "SaleCondition_Normal       uint8\n",
      "SaleCondition_Partial      uint8\n",
      "Length: 248, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('Shape:', train.shape)\n",
    "print('Dtypes:\\n', train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "Create a feature dataset that does not consist of Id and SalePrice (label: value to be predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train.copy()\n",
    "features.drop(['Id', 'SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "labels = train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(features,labels,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing v1 - Removing outliers with log transformation: Continuous Variables \n",
    "\n",
    "Using logarithmic transformation, it may help correct the distribution of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiscVal : skewness =  24.732979451706033\n",
      "PoolArea : skewness =  14.342881566937836\n",
      "LotArea : skewness =  12.025446327344339\n",
      "LowQualFinSF : skewness =  10.66505349858299\n",
      "3SsnPorch : skewness =  9.96262046395852\n",
      "KitchenAbvGr : skewness =  5.129053439295553\n",
      "BsmtFinSF2 : skewness =  4.174330005566947\n",
      "ScreenPorch : skewness =  3.967379533802487\n",
      "BsmtHalfBath : skewness =  3.89811918894981\n",
      "EnclosedPorch : skewness =  3.214887613130617\n",
      "MasVnrArea : skewness =  2.588332838278803\n",
      "OpenPorchSF : skewness =  2.2638025759950504\n",
      "BsmtFinSF1 : skewness =  1.6941364533315026\n",
      "TotalBsmtSF : skewness =  1.6330286577439608\n",
      "WoodDeckSF : skewness =  1.5027101898713007\n"
     ]
    }
   ],
   "source": [
    "# identifying continuous variables with high skewness\n",
    "continuous = ['LotArea', 'YearBuilt', 'YearRemodAdd', \n",
    "       'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n",
    "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
    "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr','TotRmsAbvGrd', 'Fireplaces', \n",
    "       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
    "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']\n",
    "array1 = skew(train[continuous])\n",
    "#the top 15 features which are the most skewed\n",
    "index1 = array1.argsort()[-15:][::-1]\n",
    "continuous_skewed=[]\n",
    "for i in index1:\n",
    "    print (continuous[i],\": skewness = \", array1[i])\n",
    "    if array1[i]>=1:\n",
    "        continuous_skewed.append(continuous[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying log transformation for selected variables\n",
    "train_out=train.copy()\n",
    "for i in continuous_skewed:\n",
    "    train_out[i] = train_out[i].map(lambda l: np.log(l) if l > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BsmtHalfBath : skewness =  36.97297297297236\n",
      "PoolArea : skewness =  13.892471985364587\n",
      "LowQualFinSF : skewness =  8.537169018827495\n",
      "3SsnPorch : skewness =  7.475352552864676\n",
      "MiscVal : skewness =  5.151007848096852\n",
      "KitchenAbvGr : skewness =  4.960618997125171\n",
      "ScreenPorch : skewness =  3.0205800205812574\n",
      "BsmtFinSF2 : skewness =  2.453380237081663\n",
      "EnclosedPorch : skewness =  2.203145749719571\n",
      "GrLivArea : skewness =  1.4168971139325073\n",
      "1stFlrSF : skewness =  1.3857782746124663\n",
      "BsmtUnfSF : skewness =  0.9266242711949279\n",
      "GarageArea : skewness =  0.8114489269622572\n",
      "2ndFlrSF : skewness =  0.7879161526110934\n",
      "TotRmsAbvGrd : skewness =  0.6758238152091317\n"
     ]
    }
   ],
   "source": [
    "#recalculating skewness of continuous variables\n",
    "array2 = skew(train_out[continuous])\n",
    "#the top 10 features which are the most skewed\n",
    "index2 = array2.argsort()[-15:][::-1]\n",
    "continuous_skewed=[]\n",
    "for i in index2: \n",
    "    print (continuous[i],\": skewness = \", array2[i])\n",
    "    if array2[i] >= 1:\n",
    "        continuous_skewed.append(continuous[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BsmtHalfBath : skewness =  3.89811918894981 \t, skewness2 =  36.97297297297236\n",
      "PoolArea : skewness =  14.342881566937836 \t, skewness2 =  13.892471985364587\n",
      "LowQualFinSF : skewness =  10.66505349858299 \t, skewness2 =  8.537169018827495\n",
      "3SsnPorch : skewness =  9.96262046395852 \t, skewness2 =  7.475352552864676\n",
      "MiscVal : skewness =  24.732979451706033 \t, skewness2 =  5.151007848096852\n",
      "KitchenAbvGr : skewness =  5.129053439295553 \t, skewness2 =  4.960618997125171\n",
      "ScreenPorch : skewness =  3.967379533802487 \t, skewness2 =  3.0205800205812574\n",
      "BsmtFinSF2 : skewness =  4.174330005566947 \t, skewness2 =  2.453380237081663\n",
      "EnclosedPorch : skewness =  3.214887613130617 \t, skewness2 =  2.203145749719571\n",
      "GrLivArea : skewness =  1.4168971139325073 \t, skewness2 =  1.4168971139325073\n",
      "1stFlrSF : skewness =  1.3857782746124663 \t, skewness2 =  1.3857782746124663\n",
      "BsmtUnfSF : skewness =  0.9266242711949279 \t, skewness2 =  0.9266242711949279\n",
      "GarageArea : skewness =  0.8114489269622572 \t, skewness2 =  0.8114489269622572\n",
      "2ndFlrSF : skewness =  0.7879161526110934 \t, skewness2 =  0.7879161526110934\n",
      "TotRmsAbvGrd : skewness =  0.6758238152091317 \t, skewness2 =  0.6758238152091317\n"
     ]
    }
   ],
   "source": [
    "#revert the log transformation if the skewness increases after log transformation\n",
    "for i in index2: \n",
    "    print (continuous[i],\": skewness = \", array1[i],\"\\t, skewness2 = \", array2[i])\n",
    "    if array2[i] >= array1[i]:\n",
    "        train_out[continuous[i]] = train[continuous[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoolArea : skewness =  13.892471985364587\n",
      "LowQualFinSF : skewness =  8.537169018827495\n",
      "3SsnPorch : skewness =  7.475352552864676\n",
      "MiscVal : skewness =  5.151007848096852\n",
      "KitchenAbvGr : skewness =  4.960618997125171\n",
      "BsmtHalfBath : skewness =  3.89811918894981\n",
      "ScreenPorch : skewness =  3.0205800205812574\n",
      "BsmtFinSF2 : skewness =  2.453380237081663\n",
      "EnclosedPorch : skewness =  2.203145749719571\n",
      "GrLivArea : skewness =  1.4168971139325073\n",
      "1stFlrSF : skewness =  1.3857782746124663\n",
      "BsmtUnfSF : skewness =  0.9266242711949279\n",
      "GarageArea : skewness =  0.8114489269622572\n",
      "2ndFlrSF : skewness =  0.7879161526110934\n",
      "TotRmsAbvGrd : skewness =  0.6758238152091317\n"
     ]
    }
   ],
   "source": [
    "#recalculating skewness of continuous variables\n",
    "array2 = skew(train_out[continuous])\n",
    "#the top 10 features which are the most skewed\n",
    "index2 = array2.argsort()[-15:][::-1]\n",
    "for i in index2: \n",
    "    print (continuous[i],\": skewness = \", array2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing v1 - Removing outliers with IQR: Continuous Variables\n",
    "\n",
    "After doing the log transformation, we selected continuous variables that still gives a skewness value of more than 1. <br> \n",
    "We then used the interquartile range (IQR) method to remove the outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1370, 248)\n",
      "(799, 248)\n"
     ]
    }
   ],
   "source": [
    "print(train_out.shape)\n",
    "# calculate interquartile range\n",
    "q25, q75 = train_out[continuous_skewed].quantile(0.25), train_out[continuous_skewed].quantile(0.75)\n",
    "iqr = q75 - q25\n",
    "# calculate the outlier cutoff\n",
    "cut_off = iqr * 1.5\n",
    "lower, upper = q25 - cut_off, q75 + cut_off\n",
    "\n",
    "train_out_2 = train_out[~((train_out>upper)).any(axis=1)]\n",
    "print(train_out_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BsmtUnfSF : skewness =  0.8134469641710275\n",
      "GarageArea : skewness =  0.7509952288155002\n",
      "2ndFlrSF : skewness =  0.6462040969748152\n"
     ]
    }
   ],
   "source": [
    "#calculating skewness of continuous variables\n",
    "array = skew(train_out_2[continuous])\n",
    "#the top 3 features which are the most skewed\n",
    "index = array.argsort()[-3:][::-1]\n",
    "for i in index: \n",
    "    print (continuous[i],\": skewness = \", array[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_liqr = train_out_2.copy()\n",
    "features_liqr.drop(['Id', 'SalePrice'], axis=1, inplace=True)\n",
    "labels_liqr = train_out_2['SalePrice']\n",
    "train_X_liqr, test_X_liqr, train_Y_liqr, test_Y_liqr = train_test_split(features_liqr,labels_liqr,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing v2 - Applying Normalization (Min-Max scaling)\n",
    "\n",
    "Transforming values so that they range between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data normalization from sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# fit scaler on training data\n",
    "norm = MinMaxScaler().fit(features)\n",
    "# transform training data\n",
    "features_norm = norm.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_norm, test_X_norm, train_Y_norm, test_Y_norm = train_test_split(features_norm,labels,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing v3 - Applying Standardization (Z-Score method)\n",
    "\n",
    "Transforming data into a distribution with a mean of 0 and standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data standardization from sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "features_stan=train.copy()\n",
    "for i in continuous:\n",
    "    # fit on training data column\n",
    "    scale = StandardScaler().fit(train[[i]])\n",
    "    # transform training data column\n",
    "    features_stan[i] = scale.transform(features_stan[[i]])\n",
    "features_stan.drop(['Id', 'SalePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_stan, test_X_stan, train_Y_stan, test_Y_stan = train_test_split(features_stan,labels,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing v4 - combine v1 and v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_liqr = train_out_2.copy()\n",
    "features_liqr.drop(['Id', 'SalePrice'], axis=1, inplace=True)\n",
    "labels_liqr = train_out_2['SalePrice']\n",
    "# data normalization from sklearn\n",
    "# fit scaler on training data\n",
    "norm = MinMaxScaler().fit(features_liqr)\n",
    "# transform training data\n",
    "features_norm = norm.transform(features_liqr)\n",
    "train_X_liqr_norm, test_X_liqr_norm, train_Y_liqr_norm, test_Y_liqr_norm = train_test_split(features_norm,labels_liqr,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing v5 - combine v1 and v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data standardization \n",
    "features_liqr_stan=train_out_2.copy()\n",
    "for i in continuous:\n",
    "    # fit on training data column\n",
    "    scale = StandardScaler().fit(train_out_2[[i]])\n",
    "    # transform training data column\n",
    "    features_liqr_stan[i] = scale.transform(features_liqr_stan[[i]])\n",
    "labels_liqr_stan = train_out_2['SalePrice']\n",
    "features_liqr_stan.drop(['Id', 'SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "train_X_liqr_stan, test_X_liqr_stan, train_Y_liqr_stan, test_Y_liqr_stan = train_test_split(features_liqr_stan,labels_liqr_stan,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Choosing variables that is correlated to SalePrice with value more than 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GrLivArea            0.709783\n",
      "GarageCars           0.636173\n",
      "GarageArea           0.607197\n",
      "TotalBsmtSF          0.603284\n",
      "1stFlrSF             0.596087\n",
      "                       ...   \n",
      "OverallQual_5       -0.383080\n",
      "GarageType_Detchd   -0.406550\n",
      "BsmtQual_TA         -0.456964\n",
      "GarageFinish_Unf    -0.485273\n",
      "KitchenQual_TA      -0.527689\n",
      "Name: SalePrice, Length: 246, dtype: float64\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "# variables most closely related to SalePrice\n",
    "corr = train.corr()['SalePrice']\n",
    "feature_select=[]\n",
    "corrshape=corr.nlargest(corr.shape[0])[1:corr.shape[0]].shape[0]\n",
    "for i in range(corrshape-1):\n",
    "    if (abs(corr.nlargest(corrshape)[1:corrshape][i])>0.2):\n",
    "        feature_select.append(corr.nlargest(corrshape)[1:corrshape].axes[0][i])\n",
    "print(corr.nlargest(corrshape)[1:corrshape])\n",
    "print(len(feature_select))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_fs1 = train[feature_select].copy()\n",
    "labels_fs1 = train['SalePrice']\n",
    "train_X_fs1, test_X_fs1, train_Y_fs1, test_Y_fs1 = train_test_split(features_fs1,labels_fs1,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data normalization after feature selection 1\n",
    "# fit scaler on training data\n",
    "norm = MinMaxScaler().fit(features[feature_select])\n",
    "# transform training data\n",
    "features_fs1_norm = norm.transform(features[feature_select])\n",
    "\n",
    "train_X_fs1_norm, test_X_fs1_norm, train_Y_fs1_norm, test_Y_fs1_norm = train_test_split(features_fs1_norm,labels_fs1,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data standardization after feature selection 1\n",
    "features_fs1_stan = features_stan[feature_select].copy()\n",
    "train_X_fs1_stan, test_X_fs1_stan, train_Y_fs1_stan, test_Y_fs1_stan = train_test_split(features_fs1_stan,labels_fs1,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GrLivArea            0.760566\n",
      "GarageCars           0.707453\n",
      "GarageArea           0.681755\n",
      "1stFlrSF             0.622325\n",
      "TotRmsAbvGrd         0.600829\n",
      "                       ...   \n",
      "GarageType_Detchd   -0.451584\n",
      "Foundation_CBlock   -0.454876\n",
      "BsmtQual_TA         -0.521637\n",
      "GarageFinish_Unf    -0.553690\n",
      "KitchenQual_TA      -0.583410\n",
      "Name: SalePrice, Length: 216, dtype: float64\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "# variables most closely related to SalePrice after removing outliers via IQR\n",
    "corr = train_out_2.corr()['SalePrice']\n",
    "feature_select2=[]\n",
    "corrshape=corr.nlargest(corr.shape[0])[1:corr.shape[0]].shape[0]\n",
    "for i in range(corrshape-1):\n",
    "    if (abs(corr.nlargest(corrshape)[1:corrshape][i])>0.2):\n",
    "        feature_select2.append(corr.nlargest(corrshape)[1:corrshape].axes[0][i])\n",
    "print(corr.nlargest(corrshape)[1:corrshape])\n",
    "print(len(feature_select))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_fs2 = train_out_2[feature_select2].copy()\n",
    "labels_fs2 = train_out_2['SalePrice']\n",
    "train_X_fs2, test_X_fs2, train_Y_fs2, test_Y_fs2 = train_test_split(features_fs2,labels_fs2,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data normalization after feature selection 2\n",
    "# fit scaler on training data\n",
    "norm = MinMaxScaler().fit(features_liqr[feature_select2])\n",
    "# transform training data\n",
    "features_fs2_norm = norm.transform(features_liqr[feature_select2])\n",
    "train_X_fs2_norm, test_X_fs2_norm, train_Y_fs2_norm, test_Y_fs2_norm = train_test_split(features_fs2_norm,labels_fs2,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data standardization after feature selection 2\n",
    "features_stan=train_out_2.copy()\n",
    "for i in continuous:\n",
    "    # fit on training data column\n",
    "    scale = StandardScaler().fit(train_out_2[[i]])\n",
    "    # transform training data column\n",
    "    features_stan[i] = scale.transform(features_stan[[i]])\n",
    "features_fs2_stan=features_stan[feature_select2].copy()\n",
    "train_X_fs2_stan, test_X_fs2_stan, train_Y_fs2_stan, test_Y_fs2_stan = train_test_split(features_fs2_stan,labels_fs2,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.04892379 0.23076923 ... 0.         1.         0.        ]\n",
      " [1.         0.02196826 0.45384615 ... 0.         1.         0.        ]\n",
      " [1.         0.04353923 0.15384615 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [1.         0.03458833 0.63846154 ... 0.         1.         0.        ]\n",
      " [1.         0.01075043 0.23076923 ... 0.         1.         0.        ]\n",
      " [1.         0.03874828 0.94615385 ... 0.         1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# using normalized variables with no feature select\n",
    "# initialisation for training data\n",
    "x_train=train_X_norm.copy()\n",
    "y=train_Y_norm.copy().to_numpy()[:,None]\n",
    "n=x_train.shape[0]\n",
    "f=x_train.shape[1]\n",
    "X = np.ones([n,f+1]) \n",
    "X[:,1:] = x_train\n",
    "print(X)\n",
    "\n",
    "# initialisation for test data \n",
    "x_test=test_X_norm.copy()\n",
    "y_test=test_Y_norm.copy().to_numpy()[:,None]\n",
    "n_test=x_test.shape[0]\n",
    "f_test=x_test.shape[1]\n",
    "X_test = np.ones([n_test,f_test+1]) \n",
    "X_test[:,1:] = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictive function definition\n",
    "def f_pred(X,w): \n",
    "    f = X.dot(w)\n",
    "    return f \n",
    "\n",
    "# loss function definition\n",
    "def loss_mse(y_pred,y): \n",
    "    n = len(y)\n",
    "    loss = 1/n* (y_pred - y).T.dot(y_pred - y) \n",
    "    return loss\n",
    "\n",
    "# loss function definition\n",
    "def loss_rmse(y_pred,y): \n",
    "    n = len(y)\n",
    "    loss = 1/n* (y_pred - y).T.dot(y_pred - y) \n",
    "    return math.sqrt(loss)\n",
    "\n",
    "# gradient function definition\n",
    "def grad_loss(y_pred,y,X):\n",
    "    n = len(y)\n",
    "    grad = 2/n* X.T.dot(y_pred-y)\n",
    "    return grad\n",
    "\n",
    "# gradient descent function definition\n",
    "def grad_desc(X, y , w_init=np.zeros(X.shape[1])[:,None] ,tau=0.01, max_iter=1000000):\n",
    "\n",
    "    L_iters = np.zeros([max_iter]) # record the loss values\n",
    "    w_iters = np.zeros([max_iter,X.shape[1]]) # record the loss values\n",
    "    w = w_init # initialization\n",
    "    for i in range(max_iter): # loop over the iterations\n",
    "        y_pred = f_pred(X,w) # linear predicition function\n",
    "        grad_f = grad_loss(y_pred,y,X) # gradient of the loss \n",
    "        w = w - tau* grad_f # update rule of gradient descent \n",
    "        L_iters[i] = loss_mse(y_pred,y) # save the current loss value \n",
    "        w_iters[i,:] = w.squeeze() # save the current w value \n",
    "        \n",
    "    return w, L_iters, w_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run gradient descent algorithm \n",
    "tau = 0.01\n",
    "w_init= np.ones(X.shape[1])[:,None]*0.01\n",
    "max_iter = 1000000\n",
    "w, L_iters, w_iters = grad_desc(X,y,w_init,tau,max_iter)\n",
    "print('train loss mse =',L_iters[-1])\n",
    "\n",
    "# calculating loss value (test)\n",
    "y_test_pred=f_pred(X_test,w)\n",
    "test_loss = loss_mse(y_test_pred,y_test)\n",
    "print('test mse loss =',test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm from scikit-learn\n",
    "regr = svm.SVR()\n",
    "regr.fit(x_train, y.ravel()) # learn the model parameters\n",
    "\n",
    "# calculating accuracy\n",
    "y_pred=regr.predict(x_train)\n",
    "loss_sklearn2 = loss_mse(y_pred[:,None],y)\n",
    "print('loss mse from sklearn svm =',loss_sklearn2)\n",
    "print (\"Train accuracy = \", regr.score(x_train, y))\n",
    "print (\"Test accuracy = \", regr.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using standardised features with no feature select\n",
    "# initialisation for training data\n",
    "x_train=train_X_stan.copy()\n",
    "y=train_Y_stan.copy().to_numpy()[:,None]\n",
    "n=x_train.shape[0]\n",
    "f=x_train.shape[1]\n",
    "X = np.ones([n,f+1]) \n",
    "X[:,1:] = x_train\n",
    "\n",
    "# initialisation for test data \n",
    "x_test=test_X_stan.copy()\n",
    "y_test=test_Y_stan.copy().to_numpy()[:,None]\n",
    "n_test=x_test.shape[0]\n",
    "f_test=x_test.shape[1]\n",
    "X_test = np.ones([n_test,f_test+1]) \n",
    "X_test[:,1:] = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run gradient descent algorithm \n",
    "tau = 0.01\n",
    "w_init= np.ones(X.shape[1])[:,None]*0.01\n",
    "max_iter = 1000000\n",
    "w, L_iters, w_iters = grad_desc(X,y,w_init,tau,max_iter)\n",
    "print('train loss mse =',L_iters[-1])\n",
    "\n",
    "# calculating loss value (test)\n",
    "y_test_pred=f_pred(X_test,w)\n",
    "test_loss = loss_mse(y_test_pred,y_test)\n",
    "print('test loss mse =',test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm from scikit-learn\n",
    "regr = svm.SVR()\n",
    "regr.fit(x_train, y.ravel()) # learn the model parameters\n",
    "\n",
    "# calculating accuracy\n",
    "y_pred=regr.predict(x_train)\n",
    "loss_sklearn2 = loss_mse(y_pred[:,None],y)\n",
    "print('loss mse from sklearn svm =',loss_sklearn2)\n",
    "print (\"Train accuracy = \", regr.score(x_train, y))\n",
    "print (\"Test accuracy = \", regr.score(x_test,y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using standardised features with removed outliers via v1\n",
    "# initialisation for training data\n",
    "x_train=train_X_liqr_stan.copy()\n",
    "y=train_Y_liqr_stan.copy().to_numpy()[:,None]\n",
    "n=x_train.shape[0]\n",
    "f=x_train.shape[1]\n",
    "X = np.ones([n,f+1]) \n",
    "X[:,1:] = x_train\n",
    "\n",
    "# initialisation for test data \n",
    "x_test=test_X_liqr_stan.copy()\n",
    "y_test=test_Y_liqr_stan.copy().to_numpy()[:,None]\n",
    "n_test=x_test.shape[0]\n",
    "f_test=x_test.shape[1]\n",
    "X_test = np.ones([n_test,f_test+1]) \n",
    "X_test[:,1:] = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run gradient descent algorithm \n",
    "tau = 0.01\n",
    "w_init= np.ones(X.shape[1])[:,None]*0.01\n",
    "max_iter = 1000000\n",
    "w, L_iters, w_iters = grad_desc(X,y,w_init,tau,max_iter)\n",
    "print('train loss mse =',L_iters[-1])\n",
    "\n",
    "# calculating loss value (test)\n",
    "y_test_pred=f_pred(X_test,w)\n",
    "test_loss = loss_mse(y_test_pred,y_test)\n",
    "print('test loss mse =',test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm from scikit-learn\n",
    "regr = svm.SVR()\n",
    "regr.fit(x_train, y.ravel()) # learn the model parameters\n",
    "\n",
    "# calculating accuracy\n",
    "y_pred=regr.predict(x_train)\n",
    "loss_sklearn2 = loss_mse(y_pred[:,None],y)\n",
    "print('loss mse from sklearn svm =',loss_sklearn2)\n",
    "print (\"Train accuracy = \", regr.score(x_train, y))\n",
    "print (\"Test accuracy = \", regr.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using normalised features with removed outliers via v1\n",
    "# initialisation for training data\n",
    "x_train=train_X_liqr_norm.copy()\n",
    "y=train_Y_liqr_norm.copy().to_numpy()[:,None]\n",
    "n=x_train.shape[0]\n",
    "f=x_train.shape[1]\n",
    "X = np.ones([n,f+1]) \n",
    "X[:,1:] = x_train\n",
    "\n",
    "# initialisation for test data \n",
    "x_test=test_X_liqr_norm.copy()\n",
    "y_test=test_Y_liqr_norm.copy().to_numpy()[:,None]\n",
    "n_test=x_test.shape[0]\n",
    "f_test=x_test.shape[1]\n",
    "X_test = np.ones([n_test,f_test+1]) \n",
    "X_test[:,1:] = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run gradient descent algorithm \n",
    "tau = 0.01\n",
    "w_init= np.ones(X.shape[1])[:,None]*0.01\n",
    "max_iter = 1000000\n",
    "w, L_iters, w_iters = grad_desc(X,y,w_init,tau,max_iter)\n",
    "print('train loss mse =',L_iters[-1])\n",
    "\n",
    "# calculating loss value (test)\n",
    "y_test_pred=f_pred(X_test,w)\n",
    "test_loss = loss_mse(y_test_pred,y_test)\n",
    "print('test loss mse =',test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm from scikit-learn\n",
    "regr = svm.SVR()\n",
    "regr.fit(x_train, y.ravel()) # learn the model parameters\n",
    "\n",
    "# calculating accuracy\n",
    "y_pred=regr.predict(x_train)\n",
    "loss_sklearn2 = loss_mse(y_pred[:,None],y)\n",
    "print('loss mse from sklearn svm =',loss_sklearn2)\n",
    "print (\"Train accuracy = \", regr.score(x_train, y))\n",
    "print (\"Test accuracy = \", regr.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature select 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using standardised features with feature select 1\n",
    "# initialisation for training data\n",
    "x_train=train_X_fs1_stan.copy()\n",
    "y=train_Y_fs1_stan.copy().to_numpy()[:,None]\n",
    "n=x_train.shape[0]\n",
    "f=x_train.shape[1]\n",
    "X = np.ones([n,f+1]) \n",
    "X[:,1:] = x_train\n",
    "\n",
    "# initialisation for test data \n",
    "x_test=test_X_fs1_stan.copy()\n",
    "y_test=test_Y_fs1_stan.copy().to_numpy()[:,None]\n",
    "n_test=x_test.shape[0]\n",
    "f_test=x_test.shape[1]\n",
    "X_test = np.ones([n_test,f_test+1]) \n",
    "X_test[:,1:] = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run gradient descent algorithm \n",
    "tau = 0.01\n",
    "w_init= np.ones(X.shape[1])[:,None]*0.01\n",
    "max_iter = 1000000\n",
    "w, L_iters, w_iters = grad_desc(X,y,w_init,tau,max_iter)\n",
    "print('train loss mse =',L_iters[-1])\n",
    "\n",
    "# calculating loss value (test)\n",
    "y_test_pred=f_pred(X_test,w)\n",
    "test_loss = loss_mse(y_test_pred,y_test)\n",
    "print('test loss mse =',test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# svm from scikit-learn\n",
    "regr = svm.SVR()\n",
    "regr.fit(x_train, y.ravel()) # learn the model parameters\n",
    "\n",
    "# calculating accuracy\n",
    "y_pred=regr.predict(x_train)\n",
    "loss_sklearn2 = loss_mse(y_pred[:,None],y)\n",
    "print('loss mse from sklearn svm =',loss_sklearn2)\n",
    "print (\"Train accuracy = \", regr.score(x_train, y))\n",
    "print (\"Test accuracy = \", regr.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using standardised features with feature select 1\n",
    "# initialisation for training data\n",
    "x_train=train_X_fs1_norm.copy()\n",
    "y=train_Y_fs1_norm.copy().to_numpy()[:,None]\n",
    "n=x_train.shape[0]\n",
    "f=x_train.shape[1]\n",
    "X = np.ones([n,f+1]) \n",
    "X[:,1:] = x_train\n",
    "\n",
    "# initialisation for test data \n",
    "x_test=test_X_fs1_norm.copy()\n",
    "y_test=test_Y_fs1_norm.copy().to_numpy()[:,None]\n",
    "n_test=x_test.shape[0]\n",
    "f_test=x_test.shape[1]\n",
    "X_test = np.ones([n_test,f_test+1]) \n",
    "X_test[:,1:] = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run gradient descent algorithm \n",
    "tau = 0.01\n",
    "w_init= np.ones(X.shape[1])[:,None]*0.01\n",
    "max_iter = 1000000\n",
    "w, L_iters, w_iters = grad_desc(X,y,w_init,tau,max_iter)\n",
    "print('train loss mse =',L_iters[-1])\n",
    "\n",
    "# calculating loss value (test)\n",
    "y_test_pred=f_pred(X_test,w)\n",
    "test_loss = loss_mse(y_test_pred,y_test)\n",
    "print('test loss mse =',test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm from scikit-learn\n",
    "regr = svm.SVR()\n",
    "regr.fit(x_train, y.ravel()) # learn the model parameters\n",
    "\n",
    "# calculating accuracy\n",
    "y_pred=regr.predict(x_train)\n",
    "loss_sklearn2 = loss_mse(y_pred[:,None],y)\n",
    "print('loss mse from sklearn svm =',loss_sklearn2)\n",
    "print (\"Train accuracy = \", regr.score(x_train, y))\n",
    "print (\"Test accuracy = \", regr.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature select 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using standardised features with feature select 2\n",
    "# initialisation for training data\n",
    "x_train=train_X_fs2_stan.copy()\n",
    "y=train_Y_fs2_stan.copy().to_numpy()[:,None]\n",
    "n=x_train.shape[0]\n",
    "f=x_train.shape[1]\n",
    "X = np.ones([n,f+1]) \n",
    "X[:,1:] = x_train\n",
    "\n",
    "# initialisation for test data \n",
    "x_test=test_X_fs2_stan.copy()\n",
    "y_test=test_Y_fs2_stan.copy().to_numpy()[:,None]\n",
    "n_test=x_test.shape[0]\n",
    "f_test=x_test.shape[1]\n",
    "X_test = np.ones([n_test,f_test+1]) \n",
    "X_test[:,1:] = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run gradient descent algorithm \n",
    "tau = 0.01\n",
    "w_init= np.ones(X.shape[1])[:,None]*0.01\n",
    "max_iter = 1000000\n",
    "w, L_iters, w_iters = grad_desc(X,y,w_init,tau,max_iter)\n",
    "print('train loss mse =',L_iters[-1])\n",
    "\n",
    "# calculating loss value (test)\n",
    "y_test_pred=f_pred(X_test,w)\n",
    "test_loss = loss_mse(y_test_pred,y_test)\n",
    "print('test loss mse =',test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# svm from scikit-learn\n",
    "regr = svm.SVR()\n",
    "regr.fit(x_train, y.ravel()) # learn the model parameters\n",
    "\n",
    "# calculating accuracy\n",
    "y_pred=regr.predict(x_train)\n",
    "loss_sklearn2 = loss_mse(y_pred[:,None],y)\n",
    "print('loss mse from sklearn svm =',loss_sklearn2)\n",
    "print (\"Train accuracy = \", regr.score(x_train, y))\n",
    "print (\"Test accuracy = \", regr.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using normalised features with feature select 2\n",
    "# initialisation for training data\n",
    "x_train=train_X_fs2_norm.copy()\n",
    "y=train_Y_fs2_norm.copy().to_numpy()[:,None]\n",
    "n=x_train.shape[0]\n",
    "f=x_train.shape[1]\n",
    "X = np.ones([n,f+1]) \n",
    "X[:,1:] = x_train\n",
    "\n",
    "# initialisation for test data \n",
    "x_test=test_X_fs2_norm.copy()\n",
    "y_test=test_Y_fs2_norm.copy().to_numpy()[:,None]\n",
    "n_test=x_test.shape[0]\n",
    "f_test=x_test.shape[1]\n",
    "X_test = np.ones([n_test,f_test+1]) \n",
    "X_test[:,1:] = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run gradient descent algorithm \n",
    "tau = 0.01\n",
    "w_init= np.ones(X.shape[1])[:,None]*0.01\n",
    "max_iter = 1000000\n",
    "w, L_iters, w_iters = grad_desc(X,y,w_init,tau,max_iter)\n",
    "print('train loss mse =',L_iters[-1])\n",
    "\n",
    "# calculating loss value (test)\n",
    "y_test_pred=f_pred(X_test,w)\n",
    "test_loss = loss_mse(y_test_pred,y_test)\n",
    "print('test loss mse =',test_loss)\n",
    "test_loss = loss_rmse(y_test_pred,y_test)\n",
    "print('test loss rmse =',test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm from scikit-learn\n",
    "regr = svm.SVR()\n",
    "regr.fit(x_train, y.ravel()) # learn the model parameters\n",
    "\n",
    "# calculating accuracy\n",
    "y_pred=regr.predict(x_train)\n",
    "loss_sklearn2 = loss_mse(y_pred[:,None],y)\n",
    "print('loss mse from sklearn svm =',loss_sklearn2)\n",
    "loss_sklearn2 = loss_rmse(y_pred[:,None],y)\n",
    "print('loss rmse from sklearn svm =',loss_sklearn2)\n",
    "print (\"Train accuracy = \", regr.score(x_train, y))\n",
    "print (\"Test accuracy = \", regr.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
